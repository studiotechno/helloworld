# Story 3.6: Qualite des Reponses & Confiance Binaire

## Status

Ready for Review

## Story

**As a** PM ou entrepreneur,
**I want** des reponses professionnelles et honnetes sur leurs limites,
**So that** je puisse faire confiance aux informations et les utiliser en reunion.

## Acceptance Criteria

1. **Given** je pose une question sur le code, **When** le systeme repond, **Then** le vocabulaire est professionnel (adapte aux PMs, pas vulgarise)
2. **And** les explications sont pedagogues (pas juste des faits, mais du contexte)
3. **And** le systeme ne dit jamais "peut-etre" ou "probablement" avec un pourcentage
4. **Given** la certitude interne du LLM est < 80%, **When** le systeme genere une reponse, **Then** il repond "Je ne suis pas en mesure de repondre avec certitude a cette question"
5. **And** il suggere comment reformuler ou quelles infos manquent
6. **Given** la certitude est >= 80%, **When** le systeme repond, **Then** la reponse est affirmative et directe
7. **And** aucune mention de niveau de confiance n'apparait

## Tasks / Subtasks

- [x] Task 1: Enhance System Prompt for Professional Vocabulary (AC: 1, 2, 3)
  - [x] Update `SYSTEM_PROMPT` in `app/api/chat/route.ts`
  - [x] Add explicit instructions for PM-friendly vocabulary
  - [x] Add instructions to avoid percentages and hedging language
  - [x] Include examples of pedagogical explanations
  - [x] Test prompt changes with various question types

- [x] Task 2: Create Confidence Detection Utility (AC: 4, 5, 6)
  - [x] Create `lib/ai/confidence.ts` module
  - [x] Implement `buildConfidenceAwarePrompt()` function
  - [x] Add confidence threshold constant (80%)
  - [x] Include prompt instructions for binary confidence behavior
  - [x] Add reformulation suggestions when uncertain

- [x] Task 3: Update Chat API for Confidence Handling (AC: 4, 5, 6, 7)
  - [x] Import confidence utilities in `app/api/chat/route.ts`
  - [x] Integrate confidence-aware prompting
  - [x] Ensure streaming responses respect confidence rules
  - [x] Test with questions that should trigger uncertainty

- [x] Task 4: Create Specialized Prompts Library (AC: 1, 2)
  - [x] Create `lib/ai/prompts/base.ts` with core PM-friendly prompt
  - [x] Create `lib/ai/prompts/index.ts` barrel export
  - [x] Define prompt templates for different question types
  - [x] Include context-building instructions

- [x] Task 5: Unit Tests (AC: 1-7)
  - [x] Test confidence utility functions
  - [x] Test prompt generation
  - [x] Test that system prompt includes all required instructions
  - [x] Manual testing with edge cases

## Dev Notes

### Previous Story Context (3.5)

Story 3.5 implemented:
- Conversation list in sidebar with date grouping
- Delete conversation functionality
- ConversationItem component with hover delete button
- Date grouping utility (`lib/utils/date-groups.ts`)

Key files from Story 3.5:
- `components/layout/ConversationItem.tsx`
- `components/layout/DeleteConversationDialog.tsx`
- `lib/utils/date-groups.ts`

### Existing Implementation Analysis

**Current System Prompt** - `app/api/chat/route.ts:52-65`:
```typescript
const SYSTEM_PROMPT = `Tu es un assistant expert qui aide les Product Managers et entrepreneurs non-techniques a comprendre leur codebase.

Ton role:
- Repondre aux questions sur le code en langage naturel
- Expliquer les concepts techniques de maniere pedagogique et accessible
- Utiliser un vocabulaire professionnel adapte aux PMs (pas de vulgarisation excessive)
- Citer les fichiers sources pertinents quand tu fais reference au code

Regles importantes:
- Reponds toujours en francais
- Si tu n'es pas certain d'une reponse, dis-le clairement: "Je ne suis pas en mesure de repondre avec certitude a cette question"
- Ne dis jamais "peut-etre" ou "probablement" avec un pourcentage de confiance
- Sois concis par defaut, mais developpe si la question est complexe
- Formate tes reponses avec du markdown pour la lisibilite`
```

The current prompt already includes some of the required behaviors but needs enhancement for:
- More explicit confidence handling
- Structured reformulation suggestions
- Pedagogical explanation patterns

### Confidence Binaire Implementation [Source: PRD FR29, UX Design]

The system should implement binary confidence:
- **Certain (>= 80%)**: Respond directly and affirmatively
- **Uncertain (< 80%)**: Say "Je ne suis pas en mesure de repondre avec certitude" + suggest reformulation

**Important**: The LLM cannot literally calculate a confidence percentage. This is implemented via prompting by:
1. Instructing the model to recognize uncertainty
2. Providing clear patterns for uncertain responses
3. Never allowing hedging language ("peut-etre", "probablement X%")

### Enhanced Prompt Structure

```typescript
// lib/ai/confidence.ts
export const CONFIDENCE_INSTRUCTIONS = `
## Gestion de la certitude

Tu dois appliquer un systeme de confiance BINAIRE:

### Quand tu ES CERTAIN:
- Reponds directement et affirmativement
- Ne mentionne JAMAIS ton niveau de confiance
- Utilise des formulations assertives: "Le systeme utilise...", "Cette fonction fait..."

### Quand tu N'ES PAS CERTAIN:
- Dis explicitement: "Je ne suis pas en mesure de repondre avec certitude a cette question."
- Explique POURQUOI tu n'es pas certain (manque d'info, code ambigu, etc.)
- Suggere comment l'utilisateur pourrait reformuler ou quelles informations aideraient

### INTERDIT:
- "Peut-etre que..."
- "Probablement..."
- "Il y a X% de chances que..."
- "Je pense que..." (utilise plutot des affirmations directes)
- "Il semble que..." (soit certain, soit dis que tu ne sais pas)
`
```

### Pedagogical Response Pattern

```typescript
// lib/ai/prompts/base.ts
export const PEDAGOGICAL_INSTRUCTIONS = `
## Style pedagogique

Tes reponses doivent:
1. **Contextualiser** - Explique le "pourquoi" avant le "quoi"
2. **Utiliser des analogies** - Compare a des concepts metier quand c'est utile
3. **Structurer** - Utilise des titres, listes, et paragraphes courts
4. **Citer les sources** - Mentionne toujours les fichiers concernes

Exemple de bonne reponse:
"L'authentification utilise OAuth 2.0 via GitHub. Concretement, quand un utilisateur clique sur 'Se connecter', il est redirige vers GitHub qui valide son identite, puis renvoie un token. Ce mecanisme est gere dans \`lib/auth/\` et les callbacks dans \`app/(auth)/callback/\`."

Exemple de mauvaise reponse:
"L'auth utilise OAuth. Le flow est standard. Voir les fichiers auth."
`
```

### Project Structure for This Story

```
lib/
├── ai/
│   ├── client.ts              # EXISTS: AI SDK setup
│   ├── confidence.ts          # NEW: Confidence handling
│   └── prompts/
│       ├── index.ts           # NEW: Barrel export
│       └── base.ts            # NEW: Base PM-friendly prompt

app/
└── api/
    └── chat/
        └── route.ts           # UPDATE: Enhanced prompting
```

### Key Constraints

1. **No LLM Fine-tuning** - All behavior changes via prompting only
2. **Streaming Compatibility** - Must work with SSE streaming
3. **Existing Tests** - Don't break existing chat functionality
4. **French Language** - All responses in French

## Testing

### Test File Locations

- `lib/ai/confidence.test.ts` - Confidence utility tests
- `lib/ai/prompts/base.test.ts` - Prompt template tests

### Test Standards

- Test framework: Vitest + Testing Library
- Co-located tests next to source files
- Test prompt structure contains required elements
- Manual testing for actual LLM behavior

### Manual Testing Checklist

1. [ ] Ask a clear question - response is direct and professional
2. [ ] Ask an ambiguous question - system admits uncertainty
3. [ ] Verify no "peut-etre" or percentage language in responses
4. [ ] Check reformulation suggestions appear when uncertain
5. [ ] Verify pedagogical explanations (context, not just facts)
6. [ ] Test with technical terms - vocabulary appropriate for PMs
7. [ ] Verify French language consistency

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-10 | 0.1 | Initial story draft | SM Agent |

## Dev Agent Record

### Agent Model Used
Claude Opus 4.5 (claude-opus-4-5-20251101)

### Debug Log References
N/A - No significant debugging required

### Completion Notes List
- Created `lib/ai/confidence.ts` with binary confidence instructions, pedagogical instructions, and professional vocabulary guidelines
- Created `lib/ai/prompts/base.ts` with complete PM-friendly system prompt builder
- Created `lib/ai/prompts/index.ts` barrel export
- Updated `app/api/chat/route.ts` to use new prompt system with repo context
- Renamed existing `lib/ai/prompts.ts` to `lib/ai/prompts-legacy.ts` to avoid path conflict
- All 25 new tests pass (confidence.test.ts: 13 tests, base.test.ts: 12 tests)
- Build passes successfully
- Note: Pre-existing test failure in DeleteAccountDialog.test.tsx unrelated to this story

### File List
**New Files:**
- `lib/ai/confidence.ts` - Binary confidence handling and pedagogical instructions
- `lib/ai/confidence.test.ts` - Confidence utility tests
- `lib/ai/prompts/base.ts` - Base system prompt builder
- `lib/ai/prompts/base.test.ts` - Prompt builder tests
- `lib/ai/prompts/index.ts` - Barrel export

**Modified Files:**
- `app/api/chat/route.ts` - Uses new prompt system with repo context

**Renamed Files:**
- `lib/ai/prompts.ts` -> `lib/ai/prompts-legacy.ts`

## QA Results
_To be filled by QA Agent_
